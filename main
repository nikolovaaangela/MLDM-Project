import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score 
from sklearn.metrics import confusion_matrix, classification_report
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Input
from sklearn.metrics import precision_score, recall_score, f1_score
import joblib
from keras.models import load_model
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, export_graphviz
import graphviz


# Function to evaluate the model and print metrics
def evaluate_model(name, y_true, y_pred, results_dict):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)

    print(f"--- {name} ---")
    print(f"Accuracy:  {accuracy:.2f}")
    print(f"Precision: {precision:.2f}")
    print(f"Recall:    {recall:.2f}")
    print(f"F1-score:  {f1:.2f}")
    print("")

    results_dict[name] = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-score": f1
    }


# Load the dataset
df = pd.read_csv("heart.csv")

# Check for missing data
print(df.isnull().sum())
# There are no missing values, no need to encode categorical variables as they are already numerical  

# Split the dataset into features and target variable
X = df.drop('target', axis=1)
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

scaler = StandardScaler()
#learns the mean and std and applies scaling
X_train_scaled = scaler.fit_transform(X_train)  
#applies the previously learned scaling to ensure that no data leaks from the test set
X_test_scaled = scaler.transform(X_test)     
# Save the scaler for later use
joblib.dump(scaler, "saved_models/scaler.pkl")


# Train the Logistic Regression model
results = {}
model = LogisticRegression()
model.fit(X_train_scaled, y_train)

# Evaluate the model and predict on the test set
y_pred = model.predict(X_test_scaled)
evaluate_model("Logistic Regression", y_test, y_pred, results)

# Feature importance for Logistic Regression
coefficients = model.coef_[0]
feature_importance_lr = pd.Series(np.abs(coefficients), index=X.columns)
feature_importance_lr = feature_importance_lr.sort_values(ascending=False)

print("Logistic Regression Feature Influence (Absolute Coefficients):\n")
print(feature_importance_lr)

# Plot feature importances
plt.figure(figsize=(10, 6))
feature_importance_lr.plot(kind='bar', title='Feature Influence (Logistic Regression)')
plt.tight_layout()
plt.show()

# Confusion Matrix for Logistic Regression
from sklearn.metrics import roc_curve, roc_auc_score
import seaborn as sns

cm_lr = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Attack', 'Attack'],
            yticklabels=['No Attack', 'Attack'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix (Logistic Regression)")
plt.tight_layout()
plt.show()

# ROC for Logistic Regression
y_proba_lr = model.predict_proba(X_test_scaled)[:, 1]
fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)
roc_auc_lr = roc_auc_score(y_test, y_proba_lr)


# Train Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predict on test set and evaluate
y_pred = rf_model.predict(X_test)
evaluate_model("Random Forest", y_test, y_pred, results)


# ROC for Random Forest
y_proba_rf = rf_model.predict_proba(X_test)[:, 1]
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)
roc_auc_rf = roc_auc_score(y_test, y_proba_rf)


# Train Gradient Boosting Classifier
gbc = GradientBoostingClassifier(n_estimators=300,
                                 learning_rate=0.1,
                                 random_state=52,
                                 max_features='sqrt',
                                  max_depth=3) 

                                 
gbc.fit(X_train, y_train)

pred_y = gbc.predict(X_test)

# Feature importance for Gradient Boosting Classifier
importances = gbc.feature_importances_
feature_names = X.columns
indices = np.argsort(importances)[::-1]  

# Plot feature importances
plt.figure(figsize=(10, 6))
plt.title("Feature Importance (Gradient Boosting)")
plt.bar(range(X.shape[1]), importances[indices], align="center")
plt.xticks(range(X.shape[1]), [feature_names[i] for i in indices], rotation=45)
plt.tight_layout()
plt.show()

evaluate_model("Gradient Boosting Classifier", y_test, pred_y, results)

# ROC for Gradient Boosting
y_proba_gbc = gbc.predict_proba(X_test)[:, 1]
fpr_gbc, tpr_gbc, _ = roc_curve(y_test, y_proba_gbc)
roc_auc_gbc = roc_auc_score(y_test, y_proba_gbc)


# Train Neural Network
classifier = Sequential()

classifier = Sequential()
classifier.add(Input(shape=(13,)))
classifier.add(Dense(units=12, kernel_initializer='uniform', activation='relu'))
classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))
classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))

classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
classifier.fit(X_train_scaled, y_train, batch_size=10, epochs=100, verbose=0)

# Evaluate ANN
loss, ann_accuracy = classifier.evaluate(X_test_scaled, y_test, verbose=0)
print("ANN Test Accuracy: {:.2f}%".format(ann_accuracy * 100))

# Predict and evaluate ANN
y_pred_ann = classifier.predict(X_test_scaled)
y_pred_ann = (y_pred_ann > 0.5)

evaluate_model("Neural Network", y_test, y_pred_ann, results)

# ROC for Neural Network
y_proba_ann = classifier.predict(X_test_scaled).ravel()
fpr_ann, tpr_ann, _ = roc_curve(y_test, y_proba_ann)
roc_auc_ann = roc_auc_score(y_test, y_proba_ann)


# Convert results to DataFrame  
results_df = pd.DataFrame(results).T
print("\nModel Performance Comparison:\n")
print(results_df.sort_values(by="F1-score", ascending=False))

# Plot ROC Curves for all models
plt.figure(figsize=(8, 6))
plt.plot(fpr_lr, tpr_lr, label=f"Logistic Regression")
plt.plot(fpr_rf, tpr_rf, label=f"Random Forest")
plt.plot(fpr_gbc, tpr_gbc, label=f"Gradient Boosting")
plt.plot(fpr_ann, tpr_ann, label=f"Neural Network")
plt.plot([0, 1], [0, 1], 'k--', label="Random Guessing")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves for all models")
plt.legend(loc="lower right")
plt.tight_layout()
plt.show()

# Train a decision tree model (just for visualization)
tree_model = DecisionTreeClassifier(max_depth=4, random_state=42)
tree_model.fit(X_train, y_train)

# Export the tree structure to DOT format
dot_data = export_graphviz(
    tree_model,
    out_file=None,
    feature_names=X.columns,
    class_names=['No Attack', 'Attack'],
    filled=True,
    rounded=True,
    special_characters=True
)

# Graph from DOT data
graph = graphviz.Source(dot_data)
graph.render("decision_tree", format="png", cleanup=True)  # Saves as decision_tree.png




import os

# Determine the best model
best_model_name = results_df["F1-score"].idxmax()
print(f"\n Best Model Based on F1-Score: {best_model_name}")

# Save the best model
model_dir = "saved_models"
os.makedirs(model_dir, exist_ok=True)

if best_model_name == "Logistic Regression":
    joblib.dump(model, f"{model_dir}/best_model.pkl")
    best_model_loaded = joblib.load(f"{model_dir}/best_model.pkl")

elif best_model_name == "Random Forest":
    joblib.dump(rf_model, f"{model_dir}/best_model.pkl")
    best_model_loaded = joblib.load(f"{model_dir}/best_model.pkl")

elif best_model_name == "Gradient Boosting Classifier":
    joblib.dump(gbc, f"{model_dir}/best_model.pkl")
    best_model_loaded = joblib.load(f"{model_dir}/best_model.pkl")

elif best_model_name == "Neural Network":
    classifier.save(f"{model_dir}/best_model.h5")
    best_model_loaded = load_model(f"{model_dir}/best_model.h5")



